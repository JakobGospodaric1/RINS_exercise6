#!/usr/bin/python3

import sys
import rospy
import cv2
import numpy as np
import tf2_geometry_msgs
import tf2_ros
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped, Vector3, Pose
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import ColorRGBA

import math

import message_filters
from cv_bridge import CvBridge, CvBridgeError

# draw elipse mask
def draw_ellipse_mask(image, ellipse):
    height, width = image.shape
    mask = np.zeros((height, width), dtype=np.uint8)

    try:
        center, axes, angle = ellipse
        center = tuple(map(int, center))
        axes = tuple(map(int, axes))
    except ValueError:
        return None

    # Check that the ellipse box has non-negative width and height
    if axes[0] <= 0 or axes[1] <= 0:
        return None

    # Draw filled ellipse on the mask
    cv2.ellipse(mask, ellipse, 255, -1)

    return mask

def average_depth_in_ellipse_optimized(depth_image, ellipse1, ellipse2):
    # Calculate the mask for the ellipse
    mask1 = draw_ellipse_mask(depth_image, ellipse1)
    mask2 = draw_ellipse_mask(depth_image, ellipse2)

    if mask1 is None or mask2 is None:
        return 0

    # Create a boolean mask
    bool_mask1 = mask1.astype(bool)
    bool_mask2 = mask2.astype(bool)

    # do bitwise and
    bool_mask = np.bitwise_xor(bool_mask1, bool_mask2)

    # Extract depth values inside the ellipse using the mask
    depths = depth_image[bool_mask]

    # Calculate the average depth of all non-zero elements
    avg_depth = np.nanmean(depths)

    return avg_depth

def avarage_color_in_ellipse_optimized(rgb_image, ellipse1, ellipse2):
    # Calculate the mask for the ellipse
    mask1 = draw_ellipse_mask(rgb_image[:, :, 0], ellipse1)
    mask2 = draw_ellipse_mask(rgb_image[:, :, 0], ellipse2)

    if mask1 is None or mask2 is None:
        return 0

    # Create a boolean mask
    bool_mask1 = mask1.astype(bool)
    bool_mask2 = mask2.astype(bool)

    # do bitwise and
    bool_mask = np.bitwise_xor(bool_mask1, bool_mask2)

    # get only ring colors
    new_color_r = rgb_image[:, :, 0] * bool_mask
    new_color_g = rgb_image[:, :, 1] * bool_mask
    new_color_b = rgb_image[:, :, 2] * bool_mask

    #new_color = np.dstack((new_color_r, new_color_g, new_color_b))
    vals_greater_than_zero = (bool_mask > 0).sum()
    
    # avreage color
    r = new_color_r.sum() / vals_greater_than_zero
    g = new_color_g.sum() / vals_greater_than_zero
    b = new_color_b.sum() / vals_greater_than_zero

    color = np.array([b, g, r])
    
    return color

class The_Ring:
    def __init__(self):
        rospy.init_node('image_converter', anonymous=True)

        # An object we use for converting images between ROS format and OpenCV format
        self.bridge = CvBridge()

        # A help variable for holding the dimensions of the image
        self.dims = (0, 0, 0)

        # Marker array object used for visualizations
        self.marker_array = MarkerArray()
        self.marker_num = 1

        # Subscribe to the image
        # self.image_sub = rospy.Subscriber("/camera/rgb/image_raw", Image, self.image_callback)
        # Subscribe to the depth topic
        # self.depth_sub = rospy.Subscriber("/camera/depth/image_raw", Image, self.depth_callback)

        # Message filering for synchronizing the rgb and depth images
        rgm_sub = message_filters.Subscriber("/camera/rgb/image_raw", Image)
        depth_sub = message_filters.Subscriber("/camera/depth/image_raw", Image)

        synchronizer = message_filters.ApproximateTimeSynchronizer([rgm_sub, depth_sub], 10, 0.1)
        synchronizer.registerCallback(self.find_rings_callback)

        # Publiser for the visualization markers
        self.markers_pub = rospy.Publisher('markers', MarkerArray, queue_size=1000)

        # Object we use for transforming between coordinate frames
        self.tf_buf = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buf)

        # cv2.destroyAllWindows()

    def get_pose(self,e,dist, avg_color, stamp):
        # Calculate the position of the detected ellipse

        k_f = 525 # kinect focal length in pixels

        elipse_x = self.dims[1] / 2 - e[0][0]
        elipse_y = self.dims[0] / 2 - e[0][1]

        angle_to_target = np.arctan2(elipse_x,k_f)

        # Get the angles in the base_link relative coordinate system
        x,y = dist*np.cos(angle_to_target), dist*np.sin(angle_to_target)

        ### Define a stamped message for transformation - directly in "base_frame"
        #point_s = PointStamped()
        #point_s.point.x = x
        #point_s.point.y = y
        #point_s.point.z = 0.3
        #point_s.header.frame_id = "base_link"
        #point_s.header.stamp = rospy.Time(0)

        # Define a stamped message for transformation - in the "camera rgb frame"
        point_s = PointStamped()
        point_s.point.x = -y
        point_s.point.y = 0
        point_s.point.z = x
        point_s.header.frame_id = "camera_rgb_optical_frame"
        point_s.header.stamp = stamp

        # Get the point in the "map" coordinate system
        try:
            point_world = self.tf_buf.transform(point_s, "map")

            #if point contains NaN or Inf, return None
            if np.isnan(point_world.point.x) or np.isnan(point_world.point.y) or np.isnan(point_world.point.z) or \
                    np.isinf(point_world.point.x) or np.isinf(point_world.point.y) or np.isinf(point_world.point.z):
                return None

            # Create a Pose object with the same position
            pose = Pose()
            pose.position.x = point_world.point.x
            pose.position.y = point_world.point.y
            pose.position.z = point_world.point.z

            pose.orientation.w = 1
            pose.orientation.x = 0
            pose.orientation.y = 0
            pose.orientation.z = 0

            # Create a marker used for visualization
            self.marker_num += 1
            marker = Marker()
            marker.header.stamp = point_world.header.stamp
            marker.header.frame_id = point_world.header.frame_id
            marker.pose = pose
            marker.type = Marker.CUBE
            marker.action = Marker.ADD
            marker.frame_locked = False
            # marker.lifetime = rospy.Duration.from_sec(10)
            marker.id = self.marker_num
            marker.scale = Vector3(0.1, 0.1, 0.1)
            marker.color = ColorRGBA(avg_color[0], avg_color[1], avg_color[2], 1)

            #append to array if there is no marker near 1m
            if len(self.marker_array.markers) == 0:
                self.marker_array.markers.append(marker)

            else:
                #if there is a marker that is nearer than n meters, make it middle value of the two
                n = 0.4
                update = False
                for m in self.marker_array.markers:
                    if np.sqrt((m.pose.position.x - marker.pose.position.x)**2 + (m.pose.position.y - marker.pose.position.y)**2 + (m.pose.position.z - marker.pose.position.z)**2) < n:
                        m.pose.position.x = (m.pose.position.x + marker.pose.position.x)/2
                        m.pose.position.y = (m.pose.position.y + marker.pose.position.y)/2
                        m.pose.position.z = (m.pose.position.z + marker.pose.position.z)/2
                        
                        #update color
                        m.color = marker.color

                        update = True
                        break

                if not update:
                    self.marker_array.markers.append(marker)               
            
            # self.marker_array.markers.append(marker)

            # print size of array
            # print(len(self.marker_array.markers))

            # publish the marker array
            self.markers_pub.publish(self.marker_array)

        except Exception as e:
            print(e)

    def find_rings_callback(self, img_msg, depth_msg):
        #print timestamp
        # print(img_msg.header.stamp)

        try:
            rgb_image = self.bridge.imgmsg_to_cv2(img_msg, "bgr8")
        except CvBridgeError as e:
            print(e)

        try:
            depth_image = self.bridge.imgmsg_to_cv2(depth_msg, "passthrough")
        except CvBridgeError as e:
            print(e)

        if depth_image is None or rgb_image is None:
            return

        # Set tnhe dimensions of the image
        self.dims = depth_image.shape


        # # Transform the image to grayscale
        img = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2GRAY)

        # where depth is the farthest, set img to 0
        img[np.isnan(depth_image)] = -1

        # Do histogram equlization
        img = cv2.equalizeHist(img)

        #view image
        cv2.imshow("img", img)
        cv2.waitKey(1)

        # Binarize the image, there are different ways to do it
        #ret, thresh = cv2.threshold(img, 50, 255, 0)
        # ret, thresh = cv2.threshold(img, 70, 255, cv2.THRESH_BINARY)
        thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 25, 30) 

        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        # # mask bottom part of image
        # masked_img = np.copy(rgb_image)
        # masked_img[rgb_image.shape[0]//2:rgb_image.shape[0], :, :] = 0

        # thresh_x = cv2.adaptiveThreshold(masked_img[:,:,0], 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 25, 40)
        # thresh_y = cv2.adaptiveThreshold(masked_img[:,:,1], 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 25, 40)
        # thresh_z = cv2.adaptiveThreshold(masked_img[:,:,2], 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 25, 40)

        # # Extract contours
        # contours_x, hierarchy = cv2.findContours(thresh_x, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        # contours_y, hierarchy = cv2.findContours(thresh_y, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        # contours_z, hierarchy = cv2.findContours(thresh_z, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

        # # find the with most contours
        # if len(contours_x) > len(contours_y) and len(contours_x) > len(contours_z):
        #     contours = contours_x
        # elif len(contours_y) > len(contours_x) and len(contours_y) > len(contours_z):
        #     contours = contours_y
        # else:
        #     contours = contours_z

        # Fit elipses to all extracted contours
        elps = []
        for cnt in contours:
            #     print cnt
            #     print cnt.shape
            if cnt.shape[0] >= 50:
                ellipse = cv2.fitEllipse(cnt)
                elps.append(ellipse)


        # Find two elipses with same centers
        candidates = []
        for n in range(len(elps)):
            for m in range(n + 1, len(elps)):
                e1 = elps[n]
                e2 = elps[m]
                dist = np.sqrt(((e1[0][0] - e2[0][0]) ** 2 + (e1[0][1] - e2[0][1]) ** 2))
                #             print dist

                # if e1 or e2 are outside of the image, skip
                if e1[0][0] < 0 or e1[0][0] > self.dims[1] or e1[0][1] < 0 or e1[0][1] > self.dims[0]:
                    continue

                # if distance > 5 continue
                if dist > 0.5:
                    continue

                # get center depth
                try:
                    depth = depth_image[int(e1[0][1]), int(e1[0][0])]
                    #get average depth of the elips e1 and e2
                    avg_depth = average_depth_in_ellipse_optimized(depth_image, e1, e2)
                except:
                    continue

                if depth == 0 or avg_depth == 0:
                    continue

                # print(depth, avg_depth)

                if depth - avg_depth < 2:
                    continue
                
                candidates.append((e1,e2))

        print("Processing is done! found", len(candidates), "candidates for rings")

        # Show the image with points
        for c in candidates:
            # the centers of the ellipses
            e1 = c[0]
            e2 = c[1]

            # add to markers
            avg_depth = average_depth_in_ellipse_optimized(depth_image, e1, e2)
            avg_color = avarage_color_in_ellipse_optimized(rgb_image, e1, e2)
            avg_color = (avg_color[0]/255, avg_color[1]/255, avg_color[2]/255)
            self.get_pose(e1, avg_depth, avg_color, img_msg.header.stamp)

            # drawing the ellipses on the image
            cv2.ellipse(rgb_image, e1, (0, 255, 0), 2)
            cv2.ellipse(rgb_image, e2, (0, 255, 0), 2)

        # Show the image
        cv2.imshow("Depth window",rgb_image)
        cv2.waitKey(50)

def main():
    ring_finder = The_Ring()

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")

    cv2.destroyAllWindows()


if __name__ == '__main__':
    main()
